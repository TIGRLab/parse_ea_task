{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ok, a bunch of stuff pasted from JV's code to understand what it does..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "import os, sys\n",
    "import logging\n",
    "import glob\n",
    "import copy\n",
    "import time\n",
    "import tempfile\n",
    "import shutil\n",
    "import yaml\n",
    "import StringIO as io\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.interpolate as interpolate\n",
    "\n",
    "import datman.utils as utils\n",
    "import datman.config as cfg\n",
    "from docopt import docopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_parser(log):\n",
    "    \"\"\"\n",
    "    This takes the EA task log file generated by e-prime and converts it into a\n",
    "    set of numpy-friendly arrays (with mixed numeric and text fields.)\n",
    "\n",
    "    pic -- 'Picture' lines, which contain the participant's ratings.\n",
    "    res -- 'Response' lines, which contain their responses (unclear)\n",
    "    vid -- 'Video' lines, which demark the start and end of trials.\n",
    "    \"\"\"\n",
    "    # substitute for GREP -- finds 'eventtype' field.\n",
    "    # required as this file has a different number of fields per line\n",
    "    logname = copy.copy(log)\n",
    "    log = open(log, \"r\").readlines()\n",
    "    pic = filter(lambda s: 'Picture' in s, log)\n",
    "    vid = filter(lambda s: 'Video' in s, log)\n",
    "\n",
    "    # write out files from stringio blobs into numpy genfromtxt\n",
    "    pic = np.genfromtxt(io.StringIO(''.join(pic)), delimiter='\\t',\n",
    "        names=['subject', 'trial', 'eventtype', 'code', 'time', 'ttime', 'uncertainty1', 'duration', 'uncertainty2', 'reqtime', 'reqduration', 'stimtype', 'pairindex'],\n",
    "        dtype=['|S64'   , int    , '|S64'     , '|S64', int   , int    , int           , int       , int           , int      , int          , '|S64'    , int])\n",
    "\n",
    "    vid = np.genfromtxt(io.StringIO(''.join(vid)), delimiter='\\t',\n",
    "        names=['subject', 'trial', 'eventtype', 'code', 'time', 'ttime', 'uncertainty1'],\n",
    "        dtype=['|S64'   , int    , '|S64'     , '|S64', int   , int    , int])\n",
    "\n",
    "    # ensure our inputs contain a 'MRI_start' string.\n",
    "    if pic[0][3] != 'MRI_start':\n",
    "        logger.error('log {} does not contain an MRI_start entry!'.format(logname))\n",
    "        raise ValueError\n",
    "    else:\n",
    "        # this is the start of the fMRI run, all times are relative to this.\n",
    "        mri_start = pic[0][7]\n",
    "        return pic, vid, mri_start\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_blocks(vid, mri_start):\n",
    "    \"\"\"\n",
    "    Takes the start time and a vid tuple list to find the relative\n",
    "    block numbers, their start times, and their type (string).\n",
    "    \"\"\"\n",
    "    blocks = []\n",
    "    onsets = []\n",
    "    for v in vid:\n",
    "\n",
    "        # we will use this to search through the response files\n",
    "        block_number = v[1]\n",
    "\n",
    "        # this is maybe useless (e.g., 'vid_4')\n",
    "        block_name = v[3]\n",
    "\n",
    "        # all time in 10000s of a sec.\n",
    "        block_start = (v[4])\n",
    "\n",
    "        # generate compressed video list\n",
    "        blocks.append((block_number, block_name, block_start))\n",
    "        onsets.append(block_start / 10000.0)\n",
    "\n",
    "    return blocks, onsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_ratings(pic, blk_start, blk_end, blk_start_time, duration):\n",
    "    \"\"\"\n",
    "    Takes the response and picture tuple lists and the beginning of the current\n",
    "    and next videos. This will search through all of the responses [vid_start\n",
    "    < x < vid_end] and grab their timestamps. For each, it will find the\n",
    "    corresponding picture rating and save that as an integer.\n",
    "\n",
    "    All times in 10,000s of a second.\n",
    "\n",
    "    102,103 -- person responses\n",
    "    104     -- MRI responses\n",
    "    \"\"\"\n",
    "    duration = int(duration)\n",
    "    ratings = []\n",
    "    pushes = []\n",
    "    if blk_end == None:\n",
    "        # find the final response number, take that as the end of our block\n",
    "        trial_list = np.linspace(blk_start, pic[-1][1], pic[-1][1]-blk_start+1)\n",
    "    else:\n",
    "        # just use the beginning of the next block as our end.\n",
    "        trial_list = np.linspace(blk_start, blk_end-1, blk_end-blk_start)\n",
    "\n",
    "    # refine trial list to include only the first, last, and button presses\n",
    "    responses = np.array(filter(lambda s: s[1] in trial_list, pic))\n",
    "    responses = np.array(filter(lambda s: 'rating' in s[3], responses))\n",
    "\n",
    "    # if the participant dosen't respond at all, freak out.\n",
    "    if len(responses) == 0:\n",
    "        ratings = np.array([5])\n",
    "        return ratings, 0, 0\n",
    "\n",
    "    for response in responses:\n",
    "        ratings.append((int(response[3][-1]), response[4]))\n",
    "\n",
    "    t = np.linspace(blk_start_time, blk_start_time+duration-1, num=duration)\n",
    "    r = np.zeros(duration)\n",
    "\n",
    "    val = 5\n",
    "    last = 0\n",
    "   # logger.debug('looping through ratings: {}'.format(ratings))\n",
    "    for rating in ratings:\n",
    "        idx = np.where(t == rating[1])[0]\n",
    "\n",
    "        # hack to save malformed data\n",
    "        if len(idx) == 0:\n",
    "            idx = [last + 1]\n",
    "        #logger.debug('last={} idx={} t={} rating={}'.format(last, idx, t, rating))\n",
    "\n",
    "        idx = int(idx[-1])  # take last element, convert to int\n",
    "        r[last:idx] = val   # fill in all the values before the button push\n",
    "        val = rating[0]     # update the value to insert\n",
    "        last = idx          # keep track of the last button push\n",
    "    r[last:] = val          # fill in the tail end of the vector with the last recorded value\n",
    "    n_pushes = len(ratings) # number of button pushes (the number of ratings)\n",
    "\n",
    "    return r, n_pushes, ratings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_column_data(blk_name, rating_file):\n",
    "    \"\"\"\n",
    "    Returns the data from the column of specified file with the specified name.\n",
    "    \"\"\"\n",
    "    # read in column names, convert to lowercase, compare with block name\n",
    "    column_names = np.genfromtxt(rating_file, delimiter=',',\n",
    "                                              dtype=str)[0].tolist()\n",
    "    column_names = map(lambda x: x.lower(), column_names)\n",
    "    column_number = np.where(np.array(column_names) == blk_name.lower())[0]\n",
    "\n",
    "    # read in actor ratings from the selected column, strip nans\n",
    "    column_data = np.genfromtxt(rating_file, delimiter=',',\n",
    "                                              dtype=float, skip_header=2)\n",
    "\n",
    "    # deal with a single value\n",
    "    if len(np.shape(column_data)) == 1:\n",
    "        column_data = column_data[column_number]\n",
    "    # deal with a column of values\n",
    "    elif len(np.shape(column_data)) == 2:\n",
    "        column_data = column_data[:,column_number]\n",
    "    # complain if the supplied rating_file is a dungparty\n",
    "    else:\n",
    "        logger.error('{} is not formatted properly!'.format(rating_file))\n",
    "        raise ValueError\n",
    "    # strip off NaN values\n",
    "    column_data = column_data[np.isfinite(column_data)]\n",
    "\n",
    "    return column_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def match_lengths(a, b):\n",
    "    \"\"\"\n",
    "    Matches the length of vector b to vector a using linear interpolation.\n",
    "    \"\"\"\n",
    "\n",
    "    interp = interpolate.interp1d(np.linspace(0, len(b)-1, len(b)), b)\n",
    "    b = interp(np.linspace(0, len(b)-1, len(a)))\n",
    "\n",
    "    return b\n",
    "\n",
    "\n",
    "def zscore(data):\n",
    "    \"\"\"\n",
    "    z-transforms input vector. If this fails, return a vector of zeros.\n",
    "    \"\"\"\n",
    "    datalength = len(data)\n",
    "    try:\n",
    "        data = (data - np.mean(data)) / np.std(data)\n",
    "    except:\n",
    "        data = np.zeros(datalength)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def r2z(data):\n",
    "    \"\"\"\n",
    "    Fischer's r-to-z transform on a matrix (elementwise).\n",
    "    \"\"\"\n",
    "    return(0.5 * np.log((1+data) / (1-data)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def process_behav_data(log, out_path, sub, trial_type, block_id):\n",
    "    \"\"\"\n",
    "    This parses the behavioural log files for a given trial type (either\n",
    "    'vid' for the empathic-accuracy videos, or 'cvid' for the circles task.\n",
    "\n",
    "    First, the logs are parsed into list of 'picture', 'response', and 'video'\n",
    "    events, as they contain a different number of columns and carry different\n",
    "    information. The 'video' list is then used to find the start of each block.\n",
    "\n",
    "    Within each block, this script goes about parsing the ratings made by\n",
    "    the particpant using 'find_ratings'. The timing is extracted from the\n",
    "    'response' list, and the actual rating is extracted from the 'picture'\n",
    "    list.\n",
    "\n",
    "    This is then compared with the hard-coded 'gold-standard' rating kept in\n",
    "    a column of the specified .csv file. The lengths of these vectors are\n",
    "    mached using linear interpolaton, and finally correlated. This correlation\n",
    "    value is used as an amplitude modulator of the stimulus box-car. Another\n",
    "    set of amplitude-modulated regressor of no interest is added using the\n",
    "    number of button presses per run.\n",
    "\n",
    "    The relationship between these ratings are written out to a .pdf file for\n",
    "    visual inspection, however, the onsets, durations, and correlation values\n",
    "    are only returned for the specified trial type. This should allow you to\n",
    "    easily write out a GLM timing file with the onsets, lengths,\n",
    "    correlations, and number of button-pushes split across trial types.\n",
    "    \"\"\"\n",
    "    print('Processing behaviour log: {} for: {}'.format(sub,log))\n",
    "    assets = '/archive/data/SPINS/metadata/design'\n",
    "\n",
    "    # make sure our trial type inputs are valid\n",
    "    if trial_type not in ['vid', 'cvid']:\n",
    "        print('trial_type input {} is incorrect: invalid vid or cvid'.format(trial_type))\n",
    "        raise ValueError\n",
    "\n",
    "    try:\n",
    "        pic, vid, mri_start = log_parser(log)\n",
    "    except Exception, e:\n",
    "        print('Failed to parse log file: {}'.format(log))\n",
    "        raise e\n",
    "\n",
    "   # logger.debug('Finding blocks')\n",
    "    blocks, onsets = find_blocks(vid, mri_start)\n",
    "   # logger.debug('Found {} blocks'.format(len(blocks)))\n",
    "\n",
    "    durations = []\n",
    "    correlations = []\n",
    "    onsets_used = []\n",
    "    button_pushes = []\n",
    "    all_ratings = []\n",
    "\n",
    "    # format our output plot\n",
    "    width, height = plt.figaspect(1.0/len(blocks))\n",
    "    fig, axs = plt.subplots(1, len(blocks), figsize=(width, height*0.8))\n",
    "\n",
    "    # Blocks seem to refer to videos within a block\n",
    "    for i in np.linspace(0, len(blocks)-1, len(blocks)).astype(int).tolist():\n",
    "        print('Processing block {}'.format(i))\n",
    "\n",
    "        blk_start = blocks[i][0]\n",
    "        blk_start_time = blocks[i][2]\n",
    "\n",
    "        # block end is the beginning of the next trial\n",
    "        try:\n",
    "            blk_end = blocks[i+1][0]\n",
    "        # unless we are on the final trial of the block, then we return None\n",
    "        except:\n",
    "            blk_end = None\n",
    "\n",
    "        blk_name = blocks[i][1]\n",
    "\n",
    "        gold_rate = find_column_data(blk_name, os.path.join(assets, 'EA-timing.csv'))\n",
    "        duration = find_column_data(blk_name, os.path.join(assets, 'EA-vid-lengths.csv'))[0]\n",
    "\n",
    "       # logger.debug('Finding ratings for block {}'.format(i))\n",
    "        subj_rate, n_pushes, ratings = find_ratings(pic, blk_start, blk_end, blk_start_time, duration*10000)\n",
    "        #logger.debug('Found {} ratings for {} events'.format(len(subj_rate), n_pushes))\n",
    "\n",
    "        # save a copy of the raw rating vector for the subject\n",
    "        np.savetxt('{}/{}_{}_DEBUG.csv'.format(out_path, sub, blk_name), subj_rate, delimiter=',')\n",
    "\n",
    "       # logger.debug('Interpolating subject ratings to match gold standard')\n",
    "        if n_pushes != 0:\n",
    "            subj_rate = match_lengths(gold_rate, subj_rate)\n",
    "        else:\n",
    "            subj_rate = np.repeat(5, len(gold_rate))\n",
    "\n",
    "        # save a copy of the length-matched rating vector for the subject\n",
    "        np.savetxt('{}/{}_{}_ratings.csv'.format(out_path, sub, blk_name), subj_rate, delimiter=',')\n",
    "\n",
    "        # z-score both ratings, correlate, and then zscore correlation value\n",
    "        #logger.debug('calcuating z-scored correlations')\n",
    "        gold_rate = zscore(gold_rate)\n",
    "        subj_rate = zscore(subj_rate)\n",
    "        corr = np.corrcoef(subj_rate, gold_rate)[1][0]\n",
    "        if np.isnan(corr):\n",
    "            corr = 0  # this happens when we get no responses\n",
    "        corr = r2z(corr)\n",
    "\n",
    "\n",
    "        #logger.debug('Adding data to plot')\n",
    "        axs[i].plot(gold_rate, color='black', linewidth=2)\n",
    "        axs[i].plot(subj_rate, color='red', linewidth=2)\n",
    "        axs[i].set_title(blk_name + ': z(r) = ' + str(corr), size=10)\n",
    "        axs[i].set_xlim((0,len(subj_rate)-1))\n",
    "        axs[i].set_xlabel('TR')\n",
    "        axs[i].set_xticklabels([])\n",
    "        axs[i].set_ylim((-3, 3))\n",
    "        if i == 0:\n",
    "            axs[i].set_ylabel('Rating (z)')\n",
    "        if i == len(blocks) -1:\n",
    "            axs[i].legend(['Actor', 'Participant'], loc='best', fontsize=10, frameon=False)\n",
    "\n",
    "       # logger.debug('Skip the \"other\" kind of task (if cvid, skip vid)')\n",
    "        if trial_type == 'vid' and blocks[i][1][0] == 'c':\n",
    "            continue\n",
    "        elif trial_type == 'cvid' and blocks[i][1][0] == 'v':\n",
    "            continue\n",
    "\n",
    "        # otherwise, save the output vectors in seconds\n",
    "        else:\n",
    "            try:\n",
    "                for r in ratings:\n",
    "                    #collate the button push times and correct for mri start_time\n",
    "                    # the correction should make them compatible with onsets_used\n",
    "                    #        appending ['new_value', 'time ms', 'block', 'vid_id']\n",
    "                    all_ratings.append((r[0],r[1] - mri_start, block_id, blocks[i][1]))\n",
    "            except TypeError:\n",
    "                print('No ratings found for block {}'.format(i))\n",
    "            onsets_used.append((blocks[i][1], onsets[i] - mri_start/10000.0, block_id))\n",
    "            durations.append(duration.tolist())\n",
    "\n",
    "            if type(corr) == int:\n",
    "                correlations.append(corr)\n",
    "            else:\n",
    "                correlations.append(corr.tolist())\n",
    "            # button pushes per minute (duration is in seconds)\n",
    "            button_pushes.append(n_pushes / (duration.tolist() / 60.0))\n",
    "\n",
    "    plot_name = os.path.splitext(os.path.basename(log))[0]\n",
    "    print('Saving figure {}.pdf'.format(plot_name))\n",
    "    fig.suptitle(plot_name, size=10)\n",
    "    fig.set_tight_layout(True)\n",
    "    fig.savefig('{}/{}_{}.pdf'.format(out_path, sub, plot_name))\n",
    "\n",
    "    return onsets_used, durations, correlations, button_pushes, all_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Not stuff that I actually need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_analysis_script(subject, inputs, input_type, config, study):\n",
    "    \"\"\"\n",
    "    This writes the analysis script to replicate the methods in Harvey et al\n",
    "    2013 Schizophrenia Bulletin. It expects timing files to exist.\n",
    "\n",
    "    Briefly, this method uses the correlation between the empathic ratings of\n",
    "    the participant and the actor from each video to generate an amplitude-\n",
    "    modulated box-car model to be fit to each time-series. This model is\n",
    "    convolved with an HRF, and is run alongside a standard boxcar. This allows\n",
    "    us to detect regions that modulate their 'activation strength' with\n",
    "    empathic accruacy, and those that generally track the watching of\n",
    "    emotionally-valenced videos (but do not parametrically modulate).\n",
    "    Since each video is of a different length, each block is encoded as such\n",
    "    in the stimulus-timing file (all times in seconds):\n",
    "        [start_time]*[amplitude]:[block_length]\n",
    "        30*5:12\n",
    "    See '-stim_times_AM2' in AFNI's 3dDeconvolve 'help' for more.\n",
    "    \"\"\"\n",
    "    study_base = config.get_study_base(study)\n",
    "    subject_dir = os.path.join(study_base, config.get_path('fmri'), 'ea', subject)\n",
    "    script = '{subject_dir}/{subject}_glm_1stlevel_{input_type}.sh'.format(\n",
    "        subject_dir=subject_dir, subject=subject, input_type=input_type)\n",
    "\n",
    "    # combine motion paramaters (glob because run does not expand * any longer)\n",
    "    f1 = glob.glob('{}/PARAMS/motion.*.01.1D'.format(subject_dir))[0]\n",
    "    f2 = glob.glob('{}/PARAMS/motion.*.02.1D'.format(subject_dir))[0]\n",
    "    f3 = glob.glob('{}/PARAMS/motion.*.03.1D'.format(subject_dir))[0]\n",
    "    rtn, out = utils.run('cat {} {} {} > {}/{}_motion.1D'.format(\n",
    "        f1, f2, f3, subject_dir, subject), specialquote=False)\n",
    "\n",
    "    # get input data, turn into a single string\n",
    "    input_list = inputs[input_type]\n",
    "    input_list.sort()\n",
    "\n",
    "    input_data = ''\n",
    "    for i in input_list:\n",
    "        input_data += '{} '.format(i)\n",
    "\n",
    "    # open up the master script, write common variables\n",
    "    f = open(script, 'wb')\n",
    "    f.write(\"\"\"#!/bin/bash\n",
    "\n",
    "# clean up\n",
    "rm {subject_dir}/*_glm_*\n",
    "\n",
    "# Empathic accuracy (with amplitude modulation) GLM for {sub}.\n",
    "3dDeconvolve \\\\\n",
    "    -input {input_data} \\\\\n",
    "    -mask {subject_dir}/anat_EPI_mask_MNI-nonlin.nii.gz \\\\\n",
    "    -ortvec {subject_dir}/{sub}_motion.1D motion_paramaters \\\\\n",
    "    -polort 4 \\\\\n",
    "    -num_stimts 1 \\\\\n",
    "    -local_times \\\\\n",
    "    -jobs 4 \\\\\n",
    "    -x1D {subject_dir}/{sub}_glm_vid_1stlevel_design.mat \\\\\n",
    "    -stim_times_AM2 1 {subject_dir}/{sub}_vid_block-times_ea.1D \\'dmBLOCK(1)\\' \\\\\n",
    "    -stim_label 1 empathic_accuracy \\\\\n",
    "    -fitts {subject_dir}/{sub}_glm_vid_1stlevel_explained.nii.gz \\\\\n",
    "    -errts {subject_dir}/{sub}_glm_vid_1stlevel_residuals.nii.gz \\\\\n",
    "    -bucket {subject_dir}/{sub}_glm_vid_1stlevel.nii.gz \\\\\n",
    "    -cbucket {subject_dir}/{sub}_glm_vid_1stlevel_coeffs.nii.gz \\\\\n",
    "    -fout \\\\\n",
    "    -tout \\\\\n",
    "    -xjpeg {subject_dir}/{sub}_glm_vid_1stlevel_matrix.jpg\n",
    "\n",
    "# Colour disciminiation (with amplitude modulation) GLM for {sub}.\n",
    "3dDeconvolve \\\\\n",
    "    -input {input_data} \\\\\n",
    "    -mask {subject_dir}/anat_EPI_mask_MNI-nonlin.nii.gz \\\\\n",
    "    -ortvec {subject_dir}/{sub}_motion.1D motion_paramaters \\\\\n",
    "    -polort 4 \\\\\n",
    "    -num_stimts 1 \\\\\n",
    "    -local_times \\\\\n",
    "    -jobs 4 \\\\\n",
    "    -x1D {subject_dir}/{sub}_glm_cvid_1stlevel_design.mat \\\\\n",
    "    -stim_times_AM2 1 {subject_dir}/{sub}_cvid_block-times_ea.1D \\'dmBLOCK(1)\\' \\\\\n",
    "    -stim_label 1 color_videos \\\\\n",
    "    -fitts {subject_dir}/{sub}_glm_cvid_1stlevel_explained.nii.gz \\\\\n",
    "    -errts {subject_dir}/{sub}_glm_cvid_1stlevel_residuals.nii.gz \\\\\n",
    "    -bucket {subject_dir}/{sub}_glm_cvid_1stlevel.nii.gz \\\\\n",
    "    -cbucket {subject_dir}/{sub}_glm_cvid_1stlevel_coeffs.nii.gz \\\\\n",
    "    -fout \\\\\n",
    "    -tout \\\\\n",
    "    -xjpeg {subject_dir}/{sub}_glm_cvid_1stlevel_matrix.jpg\n",
    "\n",
    "\"\"\".format(input_data=input_data, subject_dir=subject_dir, sub=subject))\n",
    "    f.close()\n",
    "\n",
    "    return script\n",
    "\n",
    "def get_inputs(files, config):\n",
    "    \"\"\"\n",
    "    finds the inputs for the ea experiment, 3 for each epitome stage.\n",
    "    \"\"\"\n",
    "    inputs = {}\n",
    "    for exported in config.study_config['fmri']['ea']['glm']:\n",
    "        candidates = filter(lambda x: '{}.nii.gz'.format(exported) in x, files)\n",
    "        tagged_candidates = []\n",
    "\n",
    "        # if a string entry, convert to a list so we iterate over elements, not letters\n",
    "        tags = config.study_config['fmri']['ea']['tags']\n",
    "        if type(tags) == str:\n",
    "            tags = [tags]\n",
    "\n",
    "        for tag in tags:\n",
    "            logger.debug('searching for inputs with tag _{}_'.format(tag))\n",
    "            tagged_candidates.extend(filter(lambda x: '_{}_'.format(tag) in x, candidates))\n",
    "\n",
    "        if len(tagged_candidates) == 3:\n",
    "            inputs[exported] = tagged_candidates\n",
    "        else:\n",
    "            logger.error('did not find exactly 3 inputs')\n",
    "            raise Exception(tagged_candidates)\n",
    "\n",
    "    return inputs\n",
    "\n",
    "def analyze_subject(subject, config, study):\n",
    "    \"\"\"\n",
    "    1) finds the behavioural log files\n",
    "    2) generates the stimulus timing files from these logs\n",
    "    3) finds the pre-processed fmri data\n",
    "    4) runs the standard GLM analysis on these data\n",
    "    \"\"\"\n",
    "    study_base = config.get_study_base(study)\n",
    "    resources_dir = os.path.join(study_base, config.get_path('resources'))\n",
    "    ea_dir = os.path.join(study_base, config.get_path('fmri'), 'ea')\n",
    "    output_dir = utils.define_folder(os.path.join(study_base, config.get_path('fmri'), 'ea', subject))\n",
    "\n",
    "    # check if subject has already been processed\n",
    "    if check_complete(ea_dir, subject):\n",
    "        msg = '{} already analysed'.format(subject)\n",
    "        logger.info(msg)\n",
    "        sys.exit(0)\n",
    "\n",
    "    # reset / remove error.log\n",
    "    error_log = os.path.join(output_dir, 'error.log')\n",
    "    if os.path.isfile(error_log):\n",
    "        os.remove(error_log)\n",
    "\n",
    "    # find the behavioural data, and exit if we fail to find it\n",
    "    try:\n",
    "        resdirs = glob.glob(os.path.join(resources_dir, subject + '_??'))\n",
    "        resources = []\n",
    "        for resdir in resdirs:\n",
    "            resfiles = [os.path.join(dp, f) for dp, dn, fn in os.walk(resdir) for f in fn]\n",
    "            resources.extend(resfiles)\n",
    "        logs = filter(lambda x: '.log' in x and 'UCLAEmpAcc' in x, resources)\n",
    "        logs.sort()\n",
    "    except:\n",
    "        logger.error('No BEHAV data for {}.'.format(subject))\n",
    "        sys.exit(1)\n",
    "\n",
    "    # if we have the wrong number of logs, don't guess which to use, just fail\n",
    "    if len(logs) != 3:\n",
    "        error_message = 'Did not find exactly 3 logs for {}\\nfound:{}.'.format(subject, logs)\n",
    "        logger.error(error_message)\n",
    "        with open(error_log, 'wb') as f:\n",
    "            f.write('{}\\n{}'.format(error_message, NODE))\n",
    "        sys.exit(1)\n",
    "\n",
    "    # parse and write the logs seperately for each experiment condition (video or shapes/colours video)\n",
    "    for test_type in ['vid','cvid']:\n",
    "        # extract all of the data from the logs\n",
    "        on_all, dur_all, corr_all, push_all, timings_all = [], [], [], [], []\n",
    "        try:\n",
    "            logger.info('Parsing {} logfiles for subject'.format(len(logs), subject))\n",
    "            for log in logs:\n",
    "                # extract the block id from the logfilename\n",
    "                block_id = os.path.splitext(os.path.basename(log))[0][-1]\n",
    "                on, dur, corr, push, timings = process_behav_data(log, output_dir, subject, test_type, block_id)\n",
    "                on_all.extend(on)\n",
    "                dur_all.extend(dur)\n",
    "                corr_all.extend(corr)\n",
    "                push_all.extend(push)\n",
    "                timings_all.extend(timings)\n",
    "        except Exception, e:\n",
    "            msg = 'Failed to parse logs for {}, with {}.'.format(subject, str(e))\n",
    "            logger.error(msg)\n",
    "            sys.exit(1)\n",
    "\n",
    "        # write data to stimulus timing file for AFNI, and a QC csv\n",
    "        # on_all = sorted(on_all, key=lambda x:x[1])\n",
    "        timings_all = sorted(timings_all, key=lambda x: (x[2], x[3], x[1]))    # put the responses into order\n",
    "        try:\n",
    "            logger.info('Writing stimulus data')\n",
    "            # write each stimulus time:\n",
    "            #         [start_time]*[amplitude],[buttonpushes]:[block_length]\n",
    "            #         30*5,0.002:12\n",
    "            # OFFSET 4 TRs == 8 Seconds!\n",
    "            # on = on - 8.0\n",
    "            f1 = open('{}/{}_{}_block-times_ea.1D'.format(output_dir, subject, test_type), 'wb') # stim timing file\n",
    "            f2 = open('{}/{}_{}_corr_push.csv'.format(output_dir, subject, test_type), 'wb')     # r values and num pushes / minute\n",
    "            f3 = open('{}/{}_{}_button-times.csv'.format(output_dir, subject, test_type), 'wb')  # button responses and timings\n",
    "            f4 = open('{}/{}_{}_vid-onsets.csv'.format(output_dir, subject, test_type), 'wb')    # button responses and timings\n",
    "            f2.write('correlation,n-pushes-per-minute\\n')\n",
    "            f3.write('Block_ID,Video,Response,Timing\\n')\n",
    "            f4.write('Block_ID,Video, Onset\\n')\n",
    "\n",
    "            for i in range(len(on_all)):\n",
    "                f1.write('{o:.2f}*{r:.2f},{p}:{d:.2f} '.format(o=on_all[i][1]-8.0, r=corr_all[i], p=push_all[i], d=dur_all[i]))\n",
    "                f2.write('{r:.2f},{p}\\n'.format(r=corr_all[i], p=push_all[i]))\n",
    "            for timing in timings_all:\n",
    "                f3.write('{b},{v},{r},{t:.2f}\\n'.format(b=timing[2], v=timing[3], r=timing[0], t=timing[1]))\n",
    "            for onset in on_all:\n",
    "                f4.write('{b},{r},{t:.2f}\\n'.format(b=onset[2], r=onset[0], t=onset[1]))\n",
    "            f1.write('\\n') # add newline at the end of each run (up to 3 runs.)\n",
    "        except IOError as e:\n",
    "            msg = 'Failed to open block_times & corr_push for {} with excuse {}'.format(subject, e.strerror)\n",
    "            logger.error(msg)\n",
    "        finally:\n",
    "            f1.close()\n",
    "            f2.close()\n",
    "            f3.close()\n",
    "            f4.close()\n",
    "\n",
    "    # run the GLM\n",
    "    files = glob.glob(os.path.join(ea_dir, subject + '/*.nii.gz'))\n",
    "    inputs = get_inputs(files, config)\n",
    "\n",
    "    for input_type in inputs.keys():\n",
    "\n",
    "        script = generate_analysis_script(subject, inputs, input_type, config, study)\n",
    "        rtn, out = utils.run('chmod 754 {}'.format(script))\n",
    "        rtn, out = utils.run(script)\n",
    "        if rtn:\n",
    "            logger.error('Script {} failed to run on subject {} with error:\\n{}'.format(\n",
    "                script, subject, out))\n",
    "            sys.exit(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<datman.config.config at 0x7f4b10cbcb10>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = cfg.config(study=\"SPINS\")\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_base = config.get_study_base(\"SPINS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/archive/data/SPINS/pipelines/fmri/ea'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ea_dir = os.path.join(study_base, config.get_path('fmri'), 'ea')\n",
    "\n",
    "ea_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = os.path.basename('archive/data/SPINS/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing behaviour log: SPN01_CMH_0001 for: /projects/gherman/Experimenting_notebooks/SPN01_CMH_0001-UCLAEmpAcc_part1.log\n",
      "Processing block 0\n",
      "Processing block 1\n",
      "Processing block 2\n",
      "Processing block 3\n",
      "Processing block 4\n",
      "Saving figure SPN01_CMH_0001-UCLAEmpAcc_part1.pdf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([('vid_4', 13.139199999999988, '1'),\n",
       "  ('vid_2', 234.03429999999997, '1'),\n",
       "  ('vid_5', 430.35219999999998, '1')],\n",
       " [170.0, 146.0, 111.0],\n",
       " [0.4413783349359878, 0.6528134754941348, 0.007553872913468284],\n",
       " [4.235294117647059, 6.575342465753425, 6.486486486486486],\n",
       " [(6, 257102, '1', 'vid_4'),\n",
       "  (5, 306416, '1', 'vid_4'),\n",
       "  (4, 319121, '1', 'vid_4'),\n",
       "  (3, 338011, '1', 'vid_4'),\n",
       "  (4, 396520, '1', 'vid_4'),\n",
       "  (5, 422096, '1', 'vid_4'),\n",
       "  (6, 481775, '1', 'vid_4'),\n",
       "  (7, 546135, '1', 'vid_4'),\n",
       "  (8, 565025, '1', 'vid_4'),\n",
       "  (9, 593777, '1', 'vid_4'),\n",
       "  (8, 1610824, '1', 'vid_4'),\n",
       "  (9, 1775317, '1', 'vid_4'),\n",
       "  (9, 2340511, '1', 'vid_2'),\n",
       "  (6, 2429611, '1', 'vid_2'),\n",
       "  (7, 2432620, '1', 'vid_2'),\n",
       "  (6, 2737199, '1', 'vid_2'),\n",
       "  (5, 2760435, '1', 'vid_2'),\n",
       "  (4, 2881799, '1', 'vid_2'),\n",
       "  (3, 2890993, '1', 'vid_2'),\n",
       "  (2, 2898850, '1', 'vid_2'),\n",
       "  (1, 2914898, '1', 'vid_2'),\n",
       "  (2, 3414562, '1', 'vid_2'),\n",
       "  (3, 3450168, '1', 'vid_2'),\n",
       "  (4, 3452676, '1', 'vid_2'),\n",
       "  (5, 3462037, '1', 'vid_2'),\n",
       "  (6, 3464043, '1', 'vid_2'),\n",
       "  (5, 3766617, '1', 'vid_2'),\n",
       "  (4, 3769291, '1', 'vid_2'),\n",
       "  (4, 4303893, '1', 'vid_5'),\n",
       "  (6, 4362401, '1', 'vid_5'),\n",
       "  (7, 4378282, '1', 'vid_5'),\n",
       "  (8, 4398844, '1', 'vid_5'),\n",
       "  (9, 4427764, '1', 'vid_5'),\n",
       "  (8, 5246885, '1', 'vid_5'),\n",
       "  (7, 5250061, '1', 'vid_5'),\n",
       "  (6, 5268115, '1', 'vid_5'),\n",
       "  (5, 5270790, '1', 'vid_5'),\n",
       "  (4, 5287172, '1', 'vid_5'),\n",
       "  (5, 5295865, '1', 'vid_5'),\n",
       "  (6, 5320773, '1', 'vid_5')])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log = '/projects/gherman/Experimenting_notebooks/SPN01_CMH_0001-UCLAEmpAcc_part1.log'\n",
    "output_dir = '/projects/gherman/Experimenting_notebooks/tmp'\n",
    "subject=\"SPN01_CMH_0001\"\n",
    "test_type = \"vid\"\n",
    "block_id = os.path.splitext(os.path.basename(log))[0][-1]\n",
    "\n",
    "                \n",
    "process_behav_data(log, output_dir, subject, test_type, block_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #just so I have it,\n",
    "    \n",
    "    # parse and write the logs seperately for each experiment condition (video or shapes/colours video)\n",
    "    for test_type in ['vid','cvid']:\n",
    "        # extract all of the data from the logs\n",
    "        on_all, dur_all, corr_all, push_all, timings_all = [], [], [], [], []\n",
    "        try:\n",
    "            logger.info('Parsing {} logfiles for subject'.format(len(logs), subject))\n",
    "            for log in logs:\n",
    "                # extract the block id from the logfilename\n",
    "                block_id = os.path.splitext(os.path.basename(log))[0][-1]\n",
    "                on, dur, corr, push, timings = process_behav_data(log, output_dir, subject, test_type, block_id)\n",
    "                on_all.extend(on)\n",
    "                dur_all.extend(dur)\n",
    "                corr_all.extend(corr)\n",
    "                push_all.extend(push)\n",
    "                timings_all.extend(timings)\n",
    "        except Exception, e:\n",
    "            msg = 'Failed to parse logs for {}, with {}.'.format(subject, str(e))\n",
    "            logger.error(msg)\n",
    "            sys.exit(1)\n",
    "\n",
    "        # write data to stimulus timing file for AFNI, and a QC csv\n",
    "        # on_all = sorted(on_all, key=lambda x:x[1])\n",
    "        timings_all = sorted(timings_all, key=lambda x: (x[2], x[3], x[1]))    # put the responses into order\n",
    "        try:\n",
    "            logger.info('Writing stimulus data')\n",
    "            # write each stimulus time:\n",
    "            #         [start_time]*[amplitude],[buttonpushes]:[block_length]\n",
    "            #         30*5,0.002:12\n",
    "            # OFFSET 4 TRs == 8 Seconds!\n",
    "            # on = on - 8.0\n",
    "            f1 = open('{}/{}_{}_block-times_ea.1D'.format(output_dir, subject, test_type), 'wb') # stim timing file\n",
    "            f2 = open('{}/{}_{}_corr_push.csv'.format(output_dir, subject, test_type), 'wb')     # r values and num pushes / minute\n",
    "            f3 = open('{}/{}_{}_button-times.csv'.format(output_dir, subject, test_type), 'wb')  # button responses and timings\n",
    "            f4 = open('{}/{}_{}_vid-onsets.csv'.format(output_dir, subject, test_type), 'wb')    # button responses and timings\n",
    "            f2.write('correlation,n-pushes-per-minute\\n')\n",
    "            f3.write('Block_ID,Video,Response,Timing\\n')\n",
    "            f4.write('Block_ID,Video, Onset\\n')\n",
    "\n",
    "            for i in range(len(on_all)):\n",
    "                f1.write('{o:.2f}*{r:.2f},{p}:{d:.2f} '.format(o=on_all[i][1]-8.0, r=corr_all[i], p=push_all[i], d=dur_all[i]))\n",
    "                f2.write('{r:.2f},{p}\\n'.format(r=corr_all[i], p=push_all[i]))\n",
    "            for timing in timings_all:\n",
    "                f3.write('{b},{v},{r},{t:.2f}\\n'.format(b=timing[2], v=timing[3], r=timing[0], t=timing[1]))\n",
    "            for onset in on_all:\n",
    "                f4.write('{b},{r},{t:.2f}\\n'.format(b=onset[2], r=onset[0], t=onset[1]))\n",
    "            f1.write('\\n') # add newline at the end of each run (up to 3 runs.)\n",
    "        except IOError as e:\n",
    "            msg = 'Failed to open block_times & corr_push for {} with excuse {}'.format(subject, e.strerror)\n",
    "            logger.error(msg)\n",
    "        finally:\n",
    "            f1.close()\n",
    "            f2.close()\n",
    "            f3.close()\n",
    "            f4.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
